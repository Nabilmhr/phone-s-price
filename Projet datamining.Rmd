---
title: "DATA MINING"
author: "NABIL"
date: '2024-04-15'
output: word_document
---





```{r cars}
data <- read.csv("Cellphone.csv") #charger les données
```

```{r,echo=TRUE}
library(knitr) 
library(tidyverse)
library(corrplot)
library(caret)
library(leaps)
library(scales) 
library(rpart) 
library(glmnet) 
library("ISLR") 
library(tidyverse) 
library(car) 
library(Metrics)
library(randomForest)
library(rpart.plot)
```


```{r,echo=TRUE}
# Vérifier et observer le bon format de la base de données
dim(data)
str(data)
head(data) 
summary(data)
```

```{r,echo=TRUE}
correlation <- cor(data)
corrplot(correlation, type = 'upper')
```

```{r,echo=TRUE}
# découpage de l'échantillon en échantillon d'apprentissage et de test
set.seed(100)
indxTrain = createDataPartition(data$Price,p=0.70,list=FALSE)
LAtrain= data[indxTrain,] # Echantillon d'apprentissage
LAtest = data[-indxTrain,] # Echantillon de test
Reg<-lm(Price~.,data=LAtrain)
summary(Reg)
```
```{r,echo=TRUE}
res=residuals(Reg)
plot(Reg,which=1:2)
```

```{r,echo=TRUE}
####Modèle au sens du critère AIC
RegAIC= step(Reg, trace=TRUE)
extractAIC(RegAIC)
```


```{r,echo=TRUE}

modelAIC = lm(Price ~ weight + ppi + cpu.core + cpu.freq + internal.mem + ram + 
    battery + thickness, data=LAtrain)

summary(modelAIC)
extractAIC(modelAIC)
```

```{r,echo=TRUE}
####Modèle au sens du R2 ajusté
Price.choixR2=leaps(LAtrain[,2:13],LAtrain$Price,method="adjr2",nbest=1)

#Meilleur modèle
t = (Price.choixR2$adjr2==max(Price.choixR2$adjr2))
#Liste des variables explicatives du meilleur modèle
colnames(LAtrain)[Price.choixR2$which[t]]
#Modèle sélectionné selon le R2 ajusté
modelAdjR2 = lm(Price ~ Sale + resoloution + ppi + cpu.core + cpu.freq + internal.mem + RearCam + Front_Cam + battery, data=LAtrain)
summary(modelAdjR2)


```




```{r,echo=TRUE}
####Modèle au sens du CP Mallows
#Recherche des meilleurs modèles au sens du Cp
Price.choix =leaps(LAtrain[,2:13],LAtrain$Price,method="Cp",nbest=1)
Price.choix$Cp
plot(Price.choix$size-1,Price.choix$Cp,ylab="Cp",xlab="Nombre de variables",
main="Risque pénalisé en fonction des variables")
#Meilleur modèle
t=(Price.choix$Cp==min(Price.choix$Cp))
colnames(LAtrain)[Price.choix$which[t]]
#Modèle sélectionné selon le Cp de Mallows
modelCp = lm(Price ~ Sale + resoloution + ppi + cpu.core + cpu.freq + internal.mem + Front_Cam + battery, data=LAtrain)
summary(modelCp)

```

```{r,echo=TRUE}
####Erreurs empiriques####
#modèle complet
pred = predict(Reg, newdata= LAtest)
err= mean((pred-LAtest$Price)^2)
err
#modèle AIC
predAIC = predict(modelAIC, newdata= LAtest)
errAIC= mean((predAIC-LAtest$Price)^2)
errAIC
#modèle R2 ajusté
predAdjR2 = predict(modelAdjR2, newdata= LAtest)
errAdjr2= mean((predAdjR2-LAtest$Price)^2)
errAdjr2
#modèle Cp Mallows
predCP = predict(modelCp, newdata= LAtest)
errCP= mean((predCP-LAtest$Price)^2)
errCP

```
```{r,echo=TRUE}
####Régression Polynomiale####
polyAdjR2 <- lm(Price ~ Product_id + Sale + cpu.core + poly(ppi, 2) + resoloution + weight + cpu.freq + internal.mem + poly(ram, 2) + RearCam + Front_Cam + battery + poly(thickness, 2), data = LAtrain)
summary(polyAdjR2 )
plot(polyAdjR2)
plot(polyAdjR2$residuals)
# erreur empirique
predpolyR2=predict(polyAdjR2, newdata= LAtest)
errpoly= mean((predpolyR2-LAtest$Price)^2)
#### Régression sans les coefficients non significatifs
RegReduc <- lm(Price ~ Product_id + Sale + cpu.core + poly(ppi, 2) + resoloution
+ weight + cpu.freq + internal.mem + poly(ram, 2) + Front_Cam + battery + poly(thickness, 2), data = LAtrain)
summary(RegReduc )
plot(RegReduc)
plot(RegReduc$residuals)
# Erreur empirique
predReduc=predict(RegReduc, newdata= LAtest)
errReduc= mean((predReduc-LAtest$Price)^2)
#### Compilation des erreurs de prédictions 
table.erreur <- data.frame(row.names = c("CP","R2 ajusté","AIC", "Polynomial",
"Polynomial réduit"), "MSE"=c(errCP,errAdjr2,errAIC, errpoly, errReduc))
table.erreur$RMSE= sqrt(table.erreur$MSE)
table.erreur
```

```{r,echo=TRUE}
####Modèle Ridge
# Modèle Ridge
lbd = 10^seq(10, -2, length = 100)
xtrain = model.matrix(Price ~ ., LAtrain)[, -14]
ytrain = LAtrain$Price
xtest = model.matrix(Price ~ ., LAtest)[, -14]
ytest = LAtest$Price
set.seed(100)
# Validation croisée
cv.ridge = cv.glmnet(xtrain, ytrain, alpha = 0, lambda = lbd)
cv.ridge
# Affichage de la validation croisée
plot(cv.ridge)
# Meilleure valeur de lambda
bestlam.ridge.min = cv.ridge$lambda.min
# Ajustement du modèle Ridge avec la meilleure valeur de lambda
fit.ridge = glmnet(xtrain, ytrain, alpha = 0, lambda = bestlam.ridge.min)
# Pr´ediction sur les donn´ees de test
pred.ridge = predict(fit.ridge, newx = xtest)
# Calcul de l’erreur empirique
err.ridge = mean((pred.ridge - ytest)^2)
err.ridge
####Modèle Lasso
set.seed(100)
lasso_fit <- cv.glmnet(xtrain,ytrain,alpha=1, lambda=lbd)
plot(lasso_fit, xvar = "lambda", label = TRUE)
bestlam.lasso.min=lasso_fit$lambda.min
lasso_fit_opt= glmnet(xtrain,ytrain,alpha=1,lambda =bestlam.lasso.min )
pred.lasso = predict(lasso_fit_opt,newx=xtest)
err.lasso = mean((pred.lasso-ytest)^2)
#Compilation  erreurs de prédiction Ridge Lasso
table.erreur <- data.frame(row.names = c( "Ridge", "Lasso"), "MSE"=c(err.ridge,err.lasso))
table.erreur

```


```{r,echo=TRUE}
####Arbre de décision
ctrl = rpart.control(minsplit = 10, cp = 0.002)
reg1 = rpart(Price ~ .,control=ctrl, data= LAtrain)
summary(reg1)
print(reg1)
printcp(reg1)
plotcp(reg1)

```

```{r,echo=TRUE}
cp.opt= 0.0026570
tree.opt = prune(reg1, cp = cp.opt,)
rpart.plot(tree.opt)
table_pred <- data.frame(reel = LAtest$Price, pred = predict(tree.opt, LAtest))
Rmse <- sqrt(mean((table_pred$reel-table_pred$pred)^2))
print(tree.opt)
rpart.plot(tree.opt)
# Random Forest
set.seed(12)
rf.sp=randomForest(Price~.,data = LAtrain, xtest = LAtest[,-13],
ytest=LAtest[,"Price"],ntree=1000,importance=TRUE)
plot(rf.sp)
ntree.opt = 250 # Le nombre d’arbre optimal est ntree.opt
set.seed(12)
rf.sp2=randomForest(Price~.,data = LAtrain, xtest = LAtest[,-13],
ytest=LAtest[,"Price"],ntree=ntree.opt,ntry=11,do.trace=TRUE,importance =TRUE)
pred.rf2 = rf.sp2$test$predicted
# Racine de l’erreur empirique
rmse.rf <-sqrt(mean((pred.rf2- LAtest$Price) ^2))
#Importance des variables
sort(round(importance(rf.sp2),2)[,1])
varImpPlot(rf.sp2,main="Average Importance plots")
```

